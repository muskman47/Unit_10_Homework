{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis: Seasonal Effects with Sklearn Linear Regression\n",
    "In this notebook, you will build a SKLearn linear regression model to predict Yen futures (\"settle\") returns with *lagged* Yen futures returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Futures contract on the Yen-dollar exchange rate:\n",
    "# This is the continuous chain of the futures contracts that are 1 month to expiration\n",
    "yen_futures = pd.read_csv(\n",
    "    Path(\"yen.csv\"), index_col=\"Date\", infer_datetime_format=True, parse_dates=True\n",
    ")\n",
    "yen_futures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the dataset to begin on January 1st, 1990\n",
    "yen_futures = yen_futures.loc[\"1990-01-01\":, :]\n",
    "yen_futures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series using \"Settle\" price percentage returns, drop any nan\"s, and check the results:\n",
    "# (Make sure to multiply the pct_change() results by 100)\n",
    "# In this case, you may have to replace inf, -inf values with np.nan\"s\n",
    "yen_futures['Returns'] = yen_futures.Settle.pct_change() * 100\n",
    "returns = yen_futures.replace(-np.inf, np.nan).dropna()\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagged Returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring warning that shows up\n",
    "#warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "# Create a lagged return using the shift function\n",
    "yen_futures['Lagged_Returns'] = returns.Settle.shift()\n",
    "yen_futures = yen_futures.dropna()\n",
    "yen_futures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split for the data using 2018-2019 for testing and the rest for training\n",
    "train = yen_futures[:'2017']\n",
    "test = yen_futures['2018':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create four dataframes:\n",
    "# X_train (training set using just the independent variables), X_test (test set of of just the independent variables)\n",
    "# Y_train (training set using just the \"y\" variable, i.e., \"Futures Return\"), Y_test (test set of just the \"y\" variable):\n",
    "X_train = train[\"Lagged_Returns\"].to_frame()\n",
    "X_test = test[\"Lagged_Returns\"].to_frame()\n",
    "y_train = train[\"Returns\"]\n",
    "y_test = test[\"Returns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression model and fit it to the training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit a SKLearn linear regression using just the training set (X_train, Y_train):\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions using the Testing Data\n",
    "\n",
    "Note: We want to evaluate the model using data that it has never seen before, in this case: X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction of \"y\" values using just the test dataset\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble actual y data (Y_test) with predicted y data (from just above) into two columns in a dataframe:\n",
    "Results = y_test.to_frame()\n",
    "Results[\"Predicted Return\"] = predictions\n",
    "Results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 20 predictions vs the true values\n",
    "Results[:20].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Sample Performance\n",
    "\n",
    "Evaluate the model using \"out-of-sample\" data (X_test and y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate the mean_squared_error (MSE) on actual versus predicted test \"y\" \n",
    "mse = mean_squared_error(\n",
    "    Results[\"Returns\"],\n",
    "    Results[\"Predicted Return\"]\n",
    ")\n",
    "\n",
    "# Using that mean-squared-error, calculate the root-mean-squared error (RMSE):\n",
    "out_of_sample_rmse = np.sqrt(mse)\n",
    "print(f\"Out-of-Sample Root Mean Squared Error (RMSE): {out_of_sample_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Sample Performance\n",
    "\n",
    "Evaluate the model using in-sample data (X_train and y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dataframe using just the \"y\" training data:\n",
    "in_sample_results = y_train.to_frame()\n",
    "\n",
    "# Add a column of \"in-sample\" predictions to that dataframe:  \n",
    "in_sample_results[\"In-sample Predictions\"] = model.predict(X_train)\n",
    "\n",
    "# Calculate in-sample mean_squared_error (for comparison to out-of-sample)\n",
    "mse = mean_squared_error(\n",
    "    in_sample_results[\"Returns\"],\n",
    "    in_sample_results[\"In-sample Predictions\"]\n",
    ")\n",
    "\n",
    "# Calculate in-sample root mean_squared_error (for comparison to out-of-sample)\n",
    "out_of_sample_rmse = np.sqrt(mse)\n",
    "print(f\"Out-of-Sample Root Mean Squared Error (RMSE): {out_of_sample_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR CONCLUSIONS HERE!\n",
    "\n",
    "Our model is not a great predictor of future value."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
